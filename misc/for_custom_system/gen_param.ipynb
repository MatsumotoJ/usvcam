{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A set of codes from camera parameter estimation to param.h5 generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Camera parameter estimation\n",
    "\n",
    "First, print the chessbord pattern ([chessboard_23mm.pdf](chessboard_23mm.pdf)) at actual size (no scaling). Record a video while moving the chessboard in front of cameras and save the video. Below the video file name is assumed to be \"calib_vid.mp4\". Then run the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def analyze_chessboardvid(vid_path, square_size=23, saveimg=False, frame_intv=5):\n",
    "    if saveimg:\n",
    "        os.makedirs('./tmp/', exist_ok=True)\n",
    "\n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6 * 9, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2) * square_size\n",
    "\n",
    "    vf = vid_path\n",
    "\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "    cap = cv2.VideoCapture(vf)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    im_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    im_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    for i_frame in tqdm(range(10, frame_count, frame_intv)):\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Find the chess board corners\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6))\n",
    "        if ret == True:\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            if saveimg:\n",
    "                frame2 = cv2.drawChessboardCorners(frame, (9, 6), corners2, ret)\n",
    "                outputfname = \"./tmp/\" + str(i_frame) + \".jpg\"\n",
    "                cv2.imwrite(outputfname, frame2)\n",
    "\n",
    "    with h5py.File(os.path.splitext(vid_path)[0] + '_chessb_detection.h5', mode='w') as h5file:\n",
    "\n",
    "        h5file.create_dataset('/imp', data=imgpoints)\n",
    "        h5file.create_dataset('/objp', data=objpoints)\n",
    "        h5file.create_dataset('/imsize', data=[im_w, im_h])\n",
    "\n",
    "def calibrate_camera_intrinsic(vid_path, mtx_init=None, dist_init=None, outpath=None):\n",
    "\n",
    "    if outpath is None:\n",
    "        outpath = os.path.splitext(vid_path)[0] + '_cam_intrinsic.h5'\n",
    "\n",
    "    with h5py.File(outpath, mode='w') as h5file_out:\n",
    "        with h5py.File(os.path.splitext(vid_path)[0] + '_chessb_detection.h5', mode='r') as h5file:\n",
    "            imgpoints = h5file['/imp'][()]\n",
    "            objpoints = h5file['/objp'][()]\n",
    "            imsize = h5file['/imsize'][()]\n",
    "\n",
    "        # normal camera\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (imsize[0], imsize[1]), mtx_init,\n",
    "                                                           dist_init)\n",
    "        dist = dist.ravel()\n",
    "\n",
    "        h5file_out.create_dataset('/mtx', data=mtx)\n",
    "        h5file_out.create_dataset('/dist', data=dist)\n",
    "        h5file_out.create_dataset('/im_w', data=imsize[0])\n",
    "        h5file_out.create_dataset('/im_h', data=imsize[1])\n",
    "\n",
    "        print('[Result]')\n",
    "        print('Camera matrix:')\n",
    "        print(mtx)\n",
    "        print('Distortion coeff:')\n",
    "        print(dist)\n",
    "        print('image size:')\n",
    "        print(imsize)\n",
    "        \n",
    "        \"\"\"\n",
    "        # omnidir camera\n",
    "        imgpoints2 = []\n",
    "        objpoints2 = []\n",
    "        for i in range(imgpoints.shape[0]):\n",
    "            imgpoints2.append(imgpoints[i, :, :, :])\n",
    "            objpoints2.append(np.reshape(objpoints[i, :, :], [-1, 1, 3]))\n",
    "\n",
    "        calibration_flags = cv2.omnidir.CALIB_USE_GUESS + cv2.omnidir.CALIB_FIX_SKEW + cv2.omnidir.CALIB_FIX_CENTER\n",
    "\n",
    "        rms, K, xi, D, rvecs, tvecs, idx = \\\n",
    "            cv2.omnidir.calibrate(\n",
    "                objpoints2,\n",
    "                imgpoints2,\n",
    "                (imsize[0], imsize[1]),\n",
    "                K=None,\n",
    "                xi=None,\n",
    "                D=None,\n",
    "                flags=calibration_flags,\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 1e-8)\n",
    "            )\n",
    "\n",
    "        h5file_out.create_dataset('/K', data=K)\n",
    "        h5file_out.create_dataset('/xi', data=xi)\n",
    "        h5file_out.create_dataset('/D', data=D)\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = 'calib_vid.mp4'\n",
    "analyze_chessboardvid(vid_path, saveimg=True, frame_intv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_camera_intrinsic(vid_path, outpath='cam_param.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info about camera calibration, see: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Making param.h5 file based on user inputs and the camera parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def create_paramfile(camera_calibration_file, paramfile_out_path, daq_fs=384000, daq_n_ch=4, camera_height=0.5, \n",
    "                     mic0pos=[0, 0, 0], speedOfSound = 343.0, pressure_calib=None):\n",
    "\n",
    "    with h5py.File(camera_calibration_file, mode='r') as f:\n",
    "        camera_matrix = f['/mtx'][()]\n",
    "        dist_coeff = f['/dist'][()]\n",
    "        im_w = f['/im_w'][()]\n",
    "        im_h = f['/im_h'][()]\n",
    "\n",
    "    fx, fy, ppx, ppy = camera_matrix[0][0], camera_matrix[1][1], camera_matrix[0][2], camera_matrix[1][2]\n",
    "\n",
    "    if pressure_calib is None:\n",
    "        pressure_calib = np.ones(daq_n_ch, dtype=float)\n",
    "\n",
    "    mic0pos = np.array(mic0pos, dtype=float)\n",
    "    r = np.array([1, 0, 0, 0, 1, 0, 0, 0, 1], dtype=float)\n",
    "    t = np.array([0, 0, 0], dtype=float)\n",
    "\n",
    "    with h5py.File(paramfile_out_path, mode='w') as f:\n",
    "        f.create_dataset('/camera_param/camera_height', data=camera_height)\n",
    "        f.create_dataset('/daq_param/fs', data=daq_fs)\n",
    "        f.create_dataset('/daq_param/n_ch', data=daq_n_ch)\n",
    "        f.create_dataset('/misc/speedOfSound', data=speedOfSound)\n",
    "        f.create_dataset('/misc/pressure_calib', data=pressure_calib)\n",
    "        f.create_dataset('/misc/mic0pos', data=mic0pos)\n",
    "        f.create_dataset('/camera_param/color_intrin/coeffs', data=dist_coeff)\n",
    "        f.create_dataset('/camera_param/color_intrin/fx', data=fx)\n",
    "        f.create_dataset('/camera_param/color_intrin/fy', data=fy)\n",
    "        f.create_dataset('/camera_param/color_intrin/width', data=im_w)\n",
    "        f.create_dataset('/camera_param/color_intrin/height', data=im_h)\n",
    "        f.create_dataset('/camera_param/color_intrin/ppx', data=ppx)\n",
    "        f.create_dataset('/camera_param/color_intrin/ppy', data=ppy)\n",
    "        f.create_dataset('/camera_param/depth_to_color_extrin/rotation', data=r)\n",
    "        f.create_dataset('/camera_param/depth_to_color_extrin/translation', data=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_calibration_file = 'cam_param.h5'\n",
    "paramfile_out_path = 'param.h5'\n",
    "\n",
    "### INPUT the other device info here ###########\n",
    "daq_fs = 384000              # sampling rate in Hz\n",
    "daq_n_ch = 4                 # number of channels\n",
    "camera_height = 0.5          # in meters\n",
    "mic0pos = [0.05, -0.05, 0.0]   # xyz position of mic ch-0 relative to the camera center in meters\n",
    "speedOfSound = 343.0         # in meters / sec\n",
    "################################################\n",
    "\n",
    "create_paramfile(camera_calibration_file, paramfile_out_path, daq_fs, daq_n_ch, camera_height, mic0pos, speedOfSound)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usvcam_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
